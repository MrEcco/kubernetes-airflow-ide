[core]
dags_folder = /opt/airflow/dags
base_log_folder = /opt/airflow/logs
dag_processor_manager_log_location = /opt/airflow/logs/dag_processor_manager/dag_processor_manager.log

logging_level = INFO

executor = KubernetesExecutor

sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
# fernet_key = from AIRFLOW__CORE__FERNET_KEY env

[cli]
api_client = airflow.api.client.json_client
endpoint_url = http://web:8080

[api]
auth_backend = airflow.api.auth.backend.default

[webserver]
authenticate = False
base_url = http://localhost:8080
web_server_host = 0.0.0.0
web_server_port = 8080
reload_on_plugin_change = True
dag_default_view = graph
cookie_secure = False

[scheduler]
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 5
run_duration = -1
min_file_process_interval = 5
dag_dir_list_interval = 300
print_stats_interval = 30
scheduler_health_check_threshold = 30
child_process_log_directory = /opt/airflow/logs/scheduler
scheduler_zombie_task_threshold = 300
catchup_by_default = True
max_tis_per_query = 512
max_threads = 8
authenticate = False
use_job_schedule = True

[admin]
hide_sensitive_variable_fields = False

[kubernetes]
namespace = default
multi_namespace_mode = False
in_cluster = False
config_file = /home/airflow/.kube/config

# delete_worker_pods = False # for kubernetes debug purpose

pod_template_file = /opt/airflow/podtemplate.yml
